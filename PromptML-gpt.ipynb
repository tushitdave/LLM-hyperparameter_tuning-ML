{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f4abd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.0.191\n",
    "# !pip install openai\n",
    "# !pip install xgboost\n",
    "# !pip install scikit-learn\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "286ce512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "# from termcolor import colored\n",
    "import os\n",
    "# from flaml import tune\n",
    "# from flaml import AutoML\n",
    "import scipy\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_rows', None)  # Display all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "918db4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>OverTime</th>\n",
       "      <th>SalesDpt</th>\n",
       "      <th>JobInvCut</th>\n",
       "      <th>MiddleTraining</th>\n",
       "      <th>MoovingPeople</th>\n",
       "      <th>NotSatif</th>\n",
       "      <th>LongDisWL1</th>\n",
       "      <th>LongDis</th>\n",
       "      <th>LongDisJobS1</th>\n",
       "      <th>LongDisJL1</th>\n",
       "      <th>ShortDisNotSingle</th>\n",
       "      <th>LongDisSingle</th>\n",
       "      <th>Engaged</th>\n",
       "      <th>YoungAndBadPaid</th>\n",
       "      <th>YoungNeverEngaged</th>\n",
       "      <th>BusinessTravel_Non-Travel</th>\n",
       "      <th>BusinessTravel_Travel_Frequently</th>\n",
       "      <th>BusinessTravel_Travel_Rarely</th>\n",
       "      <th>Department_Human Resources</th>\n",
       "      <th>Department_Research &amp; Development</th>\n",
       "      <th>Department_Sales</th>\n",
       "      <th>Education_1</th>\n",
       "      <th>Education_2</th>\n",
       "      <th>Education_3</th>\n",
       "      <th>Education_4</th>\n",
       "      <th>Education_5</th>\n",
       "      <th>EducationField_Human Resources</th>\n",
       "      <th>EducationField_Life Sciences</th>\n",
       "      <th>EducationField_Marketing</th>\n",
       "      <th>EducationField_Medical</th>\n",
       "      <th>EducationField_Other</th>\n",
       "      <th>EducationField_Technical Degree</th>\n",
       "      <th>EnvironmentSatisfaction_1</th>\n",
       "      <th>EnvironmentSatisfaction_2</th>\n",
       "      <th>EnvironmentSatisfaction_3</th>\n",
       "      <th>EnvironmentSatisfaction_4</th>\n",
       "      <th>JobInvolvement_1</th>\n",
       "      <th>JobInvolvement_2</th>\n",
       "      <th>JobInvolvement_3</th>\n",
       "      <th>JobInvolvement_4</th>\n",
       "      <th>JobLevel_1</th>\n",
       "      <th>JobLevel_2</th>\n",
       "      <th>JobLevel_3</th>\n",
       "      <th>JobLevel_4</th>\n",
       "      <th>JobLevel_5</th>\n",
       "      <th>JobRole_Healthcare Representative</th>\n",
       "      <th>JobRole_Human Resources</th>\n",
       "      <th>JobRole_Laboratory Technician</th>\n",
       "      <th>JobRole_Manager</th>\n",
       "      <th>JobRole_Manufacturing Director</th>\n",
       "      <th>JobRole_Research Director</th>\n",
       "      <th>JobRole_Research Scientist</th>\n",
       "      <th>JobRole_Sales Executive</th>\n",
       "      <th>JobRole_Sales Representative</th>\n",
       "      <th>JobSatisfaction_1</th>\n",
       "      <th>JobSatisfaction_2</th>\n",
       "      <th>JobSatisfaction_3</th>\n",
       "      <th>JobSatisfaction_4</th>\n",
       "      <th>MaritalStatus_Divorced</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <th>RelationshipSatisfaction_1</th>\n",
       "      <th>RelationshipSatisfaction_2</th>\n",
       "      <th>RelationshipSatisfaction_3</th>\n",
       "      <th>RelationshipSatisfaction_4</th>\n",
       "      <th>StockOptionLevel_0</th>\n",
       "      <th>StockOptionLevel_1</th>\n",
       "      <th>StockOptionLevel_2</th>\n",
       "      <th>StockOptionLevel_3</th>\n",
       "      <th>TrainingTimesLastYear_0</th>\n",
       "      <th>TrainingTimesLastYear_1</th>\n",
       "      <th>TrainingTimesLastYear_2</th>\n",
       "      <th>TrainingTimesLastYear_3</th>\n",
       "      <th>TrainingTimesLastYear_4</th>\n",
       "      <th>TrainingTimesLastYear_5</th>\n",
       "      <th>TrainingTimesLastYear_6</th>\n",
       "      <th>WorkLifeBalance_1</th>\n",
       "      <th>WorkLifeBalance_2</th>\n",
       "      <th>WorkLifeBalance_3</th>\n",
       "      <th>WorkLifeBalance_4</th>\n",
       "      <th>RelSatisf_mean_1.0</th>\n",
       "      <th>RelSatisf_mean_1.5</th>\n",
       "      <th>RelSatisf_mean_2.0</th>\n",
       "      <th>RelSatisf_mean_2.5</th>\n",
       "      <th>RelSatisf_mean_3.0</th>\n",
       "      <th>RelSatisf_mean_3.5</th>\n",
       "      <th>RelSatisf_mean_4.0</th>\n",
       "      <th>JobSatisf_mean_1.0</th>\n",
       "      <th>JobSatisf_mean_1.5</th>\n",
       "      <th>JobSatisf_mean_2.0</th>\n",
       "      <th>JobSatisf_mean_2.5</th>\n",
       "      <th>JobSatisf_mean_3.0</th>\n",
       "      <th>JobSatisf_mean_3.5</th>\n",
       "      <th>JobSatisf_mean_4.0</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>TotalSatisfaction_mean</th>\n",
       "      <th>Time_in_each_comp</th>\n",
       "      <th>Income_Distance</th>\n",
       "      <th>Hrate_Mrate</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Income_YearsComp</th>\n",
       "      <th>Fidelity</th>\n",
       "      <th>Attrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742527</td>\n",
       "      <td>1.383138</td>\n",
       "      <td>0.726020</td>\n",
       "      <td>-1.150554</td>\n",
       "      <td>-0.421642</td>\n",
       "      <td>-0.063296</td>\n",
       "      <td>-0.679146</td>\n",
       "      <td>0.245834</td>\n",
       "      <td>-1.238894</td>\n",
       "      <td>-0.774273</td>\n",
       "      <td>1.328107</td>\n",
       "      <td>-0.330471</td>\n",
       "      <td>0.223486</td>\n",
       "      <td>-0.241733</td>\n",
       "      <td>1.775509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.297775</td>\n",
       "      <td>-0.240677</td>\n",
       "      <td>1.488876</td>\n",
       "      <td>2.129306</td>\n",
       "      <td>-0.164511</td>\n",
       "      <td>0.764998</td>\n",
       "      <td>-0.368715</td>\n",
       "      <td>0.806541</td>\n",
       "      <td>0.161650</td>\n",
       "      <td>1.578035</td>\n",
       "      <td>-0.451684</td>\n",
       "      <td>-0.715919</td>\n",
       "      <td>0.328996</td>\n",
       "      <td>-0.473382</td>\n",
       "      <td>-0.620450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414363</td>\n",
       "      <td>1.284725</td>\n",
       "      <td>-1.674841</td>\n",
       "      <td>-0.057267</td>\n",
       "      <td>-0.550208</td>\n",
       "      <td>-1.167687</td>\n",
       "      <td>-0.679146</td>\n",
       "      <td>-1.155935</td>\n",
       "      <td>0.161650</td>\n",
       "      <td>-0.755860</td>\n",
       "      <td>-0.317412</td>\n",
       "      <td>5.114320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.717985</td>\n",
       "      <td>1.395198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.461466</td>\n",
       "      <td>-0.486709</td>\n",
       "      <td>1.243211</td>\n",
       "      <td>-1.150554</td>\n",
       "      <td>-0.421642</td>\n",
       "      <td>0.764998</td>\n",
       "      <td>0.252146</td>\n",
       "      <td>-1.155935</td>\n",
       "      <td>1.095346</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>-0.342465</td>\n",
       "      <td>-0.720954</td>\n",
       "      <td>0.882920</td>\n",
       "      <td>-0.544605</td>\n",
       "      <td>-0.553896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.524295</td>\n",
       "      <td>-1.274014</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>-0.877232</td>\n",
       "      <td>-0.678774</td>\n",
       "      <td>-0.615492</td>\n",
       "      <td>-0.058285</td>\n",
       "      <td>-0.595227</td>\n",
       "      <td>-0.305198</td>\n",
       "      <td>-1.090062</td>\n",
       "      <td>-0.088277</td>\n",
       "      <td>-0.723072</td>\n",
       "      <td>1.278581</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>3.106597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  OverTime  SalesDpt  JobInvCut  MiddleTraining  MoovingPeople  \\\n",
       "0       0         1         1          0               0              1   \n",
       "1       1         0         0          1               1              0   \n",
       "2       1         1         0          1               1              1   \n",
       "3       0         1         0          0               1              0   \n",
       "4       1         0         0          0               1              1   \n",
       "\n",
       "   NotSatif  LongDisWL1  LongDis  LongDisJobS1  LongDisJL1  ShortDisNotSingle  \\\n",
       "0         1           0        0             0           0                  0   \n",
       "1         0           0        0             0           0                  0   \n",
       "2         0           0        0             0           0                  0   \n",
       "3         0           0        0             0           0                  1   \n",
       "4         0           0        0             0           0                  1   \n",
       "\n",
       "   LongDisSingle  Engaged  YoungAndBadPaid  YoungNeverEngaged  \\\n",
       "0              0        0                0                  0   \n",
       "1              0        1                0                  0   \n",
       "2              0        0                0                  0   \n",
       "3              0        0                1                  0   \n",
       "4              0        0                1                  0   \n",
       "\n",
       "   BusinessTravel_Non-Travel  BusinessTravel_Travel_Frequently  \\\n",
       "0                          0                                 0   \n",
       "1                          0                                 1   \n",
       "2                          0                                 0   \n",
       "3                          0                                 1   \n",
       "4                          0                                 0   \n",
       "\n",
       "   BusinessTravel_Travel_Rarely  Department_Human Resources  \\\n",
       "0                             1                           0   \n",
       "1                             0                           0   \n",
       "2                             1                           0   \n",
       "3                             0                           0   \n",
       "4                             1                           0   \n",
       "\n",
       "   Department_Research & Development  Department_Sales  Education_1  \\\n",
       "0                                  0                 1            0   \n",
       "1                                  1                 0            1   \n",
       "2                                  1                 0            0   \n",
       "3                                  1                 0            0   \n",
       "4                                  1                 0            1   \n",
       "\n",
       "   Education_2  Education_3  Education_4  Education_5  \\\n",
       "0            1            0            0            0   \n",
       "1            0            0            0            0   \n",
       "2            1            0            0            0   \n",
       "3            0            0            1            0   \n",
       "4            0            0            0            0   \n",
       "\n",
       "   EducationField_Human Resources  EducationField_Life Sciences  \\\n",
       "0                               0                             1   \n",
       "1                               0                             1   \n",
       "2                               0                             0   \n",
       "3                               0                             1   \n",
       "4                               0                             0   \n",
       "\n",
       "   EducationField_Marketing  EducationField_Medical  EducationField_Other  \\\n",
       "0                         0                       0                     0   \n",
       "1                         0                       0                     0   \n",
       "2                         0                       0                     1   \n",
       "3                         0                       0                     0   \n",
       "4                         0                       1                     0   \n",
       "\n",
       "   EducationField_Technical Degree  EnvironmentSatisfaction_1  \\\n",
       "0                                0                          0   \n",
       "1                                0                          0   \n",
       "2                                0                          0   \n",
       "3                                0                          0   \n",
       "4                                0                          1   \n",
       "\n",
       "   EnvironmentSatisfaction_2  EnvironmentSatisfaction_3  \\\n",
       "0                          1                          0   \n",
       "1                          0                          1   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   EnvironmentSatisfaction_4  JobInvolvement_1  JobInvolvement_2  \\\n",
       "0                          0                 0                 0   \n",
       "1                          0                 0                 1   \n",
       "2                          1                 0                 1   \n",
       "3                          1                 0                 0   \n",
       "4                          0                 0                 0   \n",
       "\n",
       "   JobInvolvement_3  JobInvolvement_4  JobLevel_1  JobLevel_2  JobLevel_3  \\\n",
       "0                 1                 0           0           1           0   \n",
       "1                 0                 0           0           1           0   \n",
       "2                 0                 0           1           0           0   \n",
       "3                 1                 0           1           0           0   \n",
       "4                 1                 0           1           0           0   \n",
       "\n",
       "   JobLevel_4  JobLevel_5  JobRole_Healthcare Representative  \\\n",
       "0           0           0                                  0   \n",
       "1           0           0                                  0   \n",
       "2           0           0                                  0   \n",
       "3           0           0                                  0   \n",
       "4           0           0                                  0   \n",
       "\n",
       "   JobRole_Human Resources  JobRole_Laboratory Technician  JobRole_Manager  \\\n",
       "0                        0                              0                0   \n",
       "1                        0                              0                0   \n",
       "2                        0                              1                0   \n",
       "3                        0                              0                0   \n",
       "4                        0                              1                0   \n",
       "\n",
       "   JobRole_Manufacturing Director  JobRole_Research Director  \\\n",
       "0                               0                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "\n",
       "   JobRole_Research Scientist  JobRole_Sales Executive  \\\n",
       "0                           0                        1   \n",
       "1                           1                        0   \n",
       "2                           0                        0   \n",
       "3                           1                        0   \n",
       "4                           0                        0   \n",
       "\n",
       "   JobRole_Sales Representative  JobSatisfaction_1  JobSatisfaction_2  \\\n",
       "0                             0                  0                  0   \n",
       "1                             0                  0                  1   \n",
       "2                             0                  0                  0   \n",
       "3                             0                  0                  0   \n",
       "4                             0                  0                  1   \n",
       "\n",
       "   JobSatisfaction_3  JobSatisfaction_4  MaritalStatus_Divorced  \\\n",
       "0                  0                  1                       0   \n",
       "1                  0                  0                       0   \n",
       "2                  1                  0                       0   \n",
       "3                  1                  0                       0   \n",
       "4                  0                  0                       0   \n",
       "\n",
       "   MaritalStatus_Married  MaritalStatus_Single  RelationshipSatisfaction_1  \\\n",
       "0                      0                     1                           1   \n",
       "1                      1                     0                           0   \n",
       "2                      0                     1                           0   \n",
       "3                      1                     0                           0   \n",
       "4                      1                     0                           0   \n",
       "\n",
       "   RelationshipSatisfaction_2  RelationshipSatisfaction_3  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           1                           0   \n",
       "3                           0                           1   \n",
       "4                           0                           0   \n",
       "\n",
       "   RelationshipSatisfaction_4  StockOptionLevel_0  StockOptionLevel_1  \\\n",
       "0                           0                   1                   0   \n",
       "1                           1                   0                   1   \n",
       "2                           0                   1                   0   \n",
       "3                           0                   1                   0   \n",
       "4                           1                   0                   1   \n",
       "\n",
       "   StockOptionLevel_2  StockOptionLevel_3  TrainingTimesLastYear_0  \\\n",
       "0                   0                   0                        1   \n",
       "1                   0                   0                        0   \n",
       "2                   0                   0                        0   \n",
       "3                   0                   0                        0   \n",
       "4                   0                   0                        0   \n",
       "\n",
       "   TrainingTimesLastYear_1  TrainingTimesLastYear_2  TrainingTimesLastYear_3  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        1   \n",
       "2                        0                        0                        1   \n",
       "3                        0                        0                        1   \n",
       "4                        0                        0                        1   \n",
       "\n",
       "   TrainingTimesLastYear_4  TrainingTimesLastYear_5  TrainingTimesLastYear_6  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "\n",
       "   WorkLifeBalance_1  WorkLifeBalance_2  WorkLifeBalance_3  WorkLifeBalance_4  \\\n",
       "0                  1                  0                  0                  0   \n",
       "1                  0                  0                  1                  0   \n",
       "2                  0                  0                  1                  0   \n",
       "3                  0                  0                  1                  0   \n",
       "4                  0                  0                  1                  0   \n",
       "\n",
       "   RelSatisf_mean_1.0  RelSatisf_mean_1.5  RelSatisf_mean_2.0  \\\n",
       "0                   0                   1                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   RelSatisf_mean_2.5  RelSatisf_mean_3.0  RelSatisf_mean_3.5  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   1   \n",
       "2                   0                   1                   0   \n",
       "3                   0                   0                   1   \n",
       "4                   1                   0                   0   \n",
       "\n",
       "   RelSatisf_mean_4.0  JobSatisf_mean_1.0  JobSatisf_mean_1.5  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   JobSatisf_mean_2.0  JobSatisf_mean_2.5  JobSatisf_mean_3.0  \\\n",
       "0                   0                   0                   0   \n",
       "1                   1                   0                   0   \n",
       "2                   0                   1                   0   \n",
       "3                   0                   0                   1   \n",
       "4                   0                   1                   0   \n",
       "\n",
       "   JobSatisf_mean_3.5  JobSatisf_mean_4.0  DailyRate  HourlyRate  MonthlyRate  \\\n",
       "0                   1                   0   0.742527    1.383138     0.726020   \n",
       "1                   0                   0  -1.297775   -0.240677     1.488876   \n",
       "2                   0                   0   1.414363    1.284725    -1.674841   \n",
       "3                   0                   0   1.461466   -0.486709     1.243211   \n",
       "4                   0                   0  -0.524295   -1.274014     0.325900   \n",
       "\n",
       "   PercentSalaryHike  TotalWorkingYears  YearsInCurrentRole  \\\n",
       "0          -1.150554          -0.421642           -0.063296   \n",
       "1           2.129306          -0.164511            0.764998   \n",
       "2          -0.057267          -0.550208           -1.167687   \n",
       "3          -1.150554          -0.421642            0.764998   \n",
       "4          -0.877232          -0.678774           -0.615492   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager  TotalSatisfaction_mean  \\\n",
       "0                -0.679146              0.245834               -1.238894   \n",
       "1                -0.368715              0.806541                0.161650   \n",
       "2                -0.679146             -1.155935                0.161650   \n",
       "3                 0.252146             -1.155935                1.095346   \n",
       "4                -0.058285             -0.595227               -0.305198   \n",
       "\n",
       "   Time_in_each_comp  Income_Distance  Hrate_Mrate  Stability  \\\n",
       "0          -0.774273         1.328107    -0.330471   0.223486   \n",
       "1           1.578035        -0.451684    -0.715919   0.328996   \n",
       "2          -0.755860        -0.317412     5.114320   0.000000   \n",
       "3           0.031312        -0.342465    -0.720954   0.882920   \n",
       "4          -1.090062        -0.088277    -0.723072   1.278581   \n",
       "\n",
       "   Income_YearsComp  Fidelity  Attrition  \n",
       "0         -0.241733  1.775509          1  \n",
       "1         -0.473382 -0.620450          0  \n",
       "2         -0.717985  1.395198          1  \n",
       "3         -0.544605 -0.553896          0  \n",
       "4          0.108800  3.106597          0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/tushitdave/Desktop/AutomL-GPT/dataset/attrition_final.csv\")\n",
    "df.drop(['Unnamed: 0'] , axis = 1 , inplace = True)\n",
    "first_column = df.pop('Attrition') \n",
    "df['Attrition'] = first_column \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6bf98e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2940, 111)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91b59391",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = defaultdict(list)\n",
    "with open('/Users/tushitdave/Desktop/AutomL-GPT/dataset/attrition_features_data.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        feature, category = line.strip().strip('.').split(': ')\n",
    "        feature_names[category].append(feature)\n",
    "\n",
    "num_feats = feature_names['continuous']\n",
    "nom_feats = feature_names['descrete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b9ed7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "347ba563",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, :-1].to_numpy()\n",
    "y_train = train['Attrition'].to_numpy()\n",
    "\n",
    "X_test = test.iloc[:, :-1].to_numpy()\n",
    "y_test = test['Attrition'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20da4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/Users/tushitdave/Desktop/AutomL-GPT/open_ai_key_mngt/key.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    api_key = config['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d35a28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chat_openai(openai_api_key, temperature):\n",
    "\n",
    "    llm = ChatOpenAI(temperature=temperature, openai_api_key=openai_api_key)\n",
    "    memory = ConversationBufferMemory(return_messages=True)\n",
    "    return llm, memory\n",
    "\n",
    "# Example usage:\n",
    "api_key = api_key\n",
    "llm, memory = initialize_chat_openai(api_key, temperature=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea9edcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_report(df, num_feats, nom_feats):\n",
    "   \n",
    "    # Last column is the label\n",
    "    target = df.iloc[:, -1]\n",
    "    features = df.iloc[:, :-1]\n",
    "\n",
    "    # General dataset info\n",
    "    num_instances = len(df)\n",
    "    num_features = features.shape[1]\n",
    "\n",
    "    # Label class analysis\n",
    "    class_counts = target.value_counts()\n",
    "    class_distribution = class_counts / num_instances\n",
    "    if any(class_distribution < 0.3) or any(class_distribution > 0.7):\n",
    "        class_imbalance = True\n",
    "    else:\n",
    "        class_imbalance = False\n",
    "\n",
    "    # Create a text report\n",
    "    report = f\"\"\"Data Characteristics Report:\n",
    "\n",
    "- General information:\n",
    "  - Number of Instances: {num_instances}\n",
    "  - Number of Features: {num_features}\n",
    "\n",
    "- Class distribution analysis:\n",
    "  - Class Distribution: {class_distribution.to_string()}\n",
    "  {'Warning: Class imbalance detected.' if class_imbalance else ''}\n",
    "\n",
    "- Feature analysis:\n",
    "  - Feature names: {features.columns.to_list()}\n",
    "  - Number of numerical features: {len(num_feats)}\n",
    "  - Number of nominal features: {len(nom_feats)}\n",
    "  - Nominal feature names: {nom_feats}\n",
    "\"\"\"\n",
    "   \n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9593c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = data_report(df, num_feats, nom_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ea2cd",
   "metadata": {},
   "source": [
    "#### Prompt for finding best hyper-parameters and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8de8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a system message\n",
    "system_message = f\"\"\"\n",
    "As a senior data scientist, your responsibility is to lead the utilization of an AutoML tool \n",
    "in the pursuit of identifying optimal XGBoost model configurations for a specific binary classification \n",
    "dataset. Your pivotal role encompasses a comprehensive understanding of the dataset's unique attributes, \n",
    "the proposal of appropriate evaluation metrics, definition of hyperparameters, and the delineation of their \n",
    "search ranges. Moreover, you are tasked with in-depth analysis of the obtained results and the iterative \n",
    "refinement of model configurations to achieve the best possible outcomes. Your expertise will be instrumental \n",
    "in achieving success in this endeavor.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "699feb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_metrics(report):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        Our mission is to tackle a classification problem utilizing a HR Attrition dataset from IBM. \n",
    "        This dataset presents us with two critical classes: \"No-Attrition\" (label: 0), indicating individuals \n",
    "        with no intention to leave the organization, and \"Yes-Attrition\" (label: 1), signifying individuals \n",
    "        inclined towards leaving the organization. \n",
    "\n",
    "        To shed light on this dataset, here are some of its pivotal characteristics:\n",
    "        {report}.\n",
    "\n",
    "        Your precise objective is to propose a hyperparameter optimization metric ideally suited for training \n",
    "        an XGBoost model. The utmost priority is for the model to adeptly discern instances of genuine \n",
    "        attrition (i.e., 'Yes-Attrition') while minimizing the generation of false positives on non-attrition \n",
    "        cases (i.e., 'No-Attrition'). \n",
    "\n",
    "        In light of the context and the dataset's unique features, kindly recommend one of the following \n",
    "        built-in metrics, tailored for this specific task:\n",
    "        - 'accuracy'\n",
    "        - 'roc_auc' (Receiver Operating Characteristic Area Under the Curve score)\n",
    "        - 'f1' (F1 score)\n",
    "        - 'balanced_accuracy' (This metric calculates the average recall score per class, providing a fair \n",
    "          evaluation, especially in the presence of class imbalance)\n",
    "        - 'average_precision'\n",
    "        - 'precision'\n",
    "        - 'recall'\n",
    "        - 'neg_brier_score'\n",
    "\n",
    "        Please preface your response with a succinct explanation of your selection rationale. Subsequently, \n",
    "        provide the name of your recommended metric, encapsulated between the markers [BEGIN] and [END], \n",
    "        as a standalone string.\n",
    "        We kindly request that you do not share additional settings or configurations.\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a0821ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_initial_search_space():\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        Leveraging your deep understanding of XGBoost and established machine learning best practices, \n",
    "        your primary objective is to propose a precise initial hyperparameter search space.\n",
    "\n",
    "        The tunable hyperparameters include:\n",
    "        - n_estimators (integer): The number of boosting rounds or trees to be trained. Consider \n",
    "          values between 50 and 300.\n",
    "        - max_depth (integer): The maximum depth allowed for individual trees. Suggest values \n",
    "          within the range of 3 to 15.\n",
    "        - min_child_weight (integer or float): The minimum sum of instance weight (hessian) \n",
    "          required in a leaf node. Recommend values between 1 and 10.\n",
    "        - gamma (float): The minimum loss reduction required to perform an additional partition \n",
    "          on a leaf node of the tree. Suggest values between 0.0 and 0.3.\n",
    "        - scale_pos_weight (float): A parameter used to balance positive and negative weights. \n",
    "          Propose values near 1.0.\n",
    "        - learning_rate (float): The step size shrinkage applied during each boosting round to \n",
    "          mitigate overfitting. Consider values from 0.01 to 0.3.\n",
    "        - subsample (float): The fraction of training data randomly sampled to train each tree. \n",
    "          Recommend values between 0.6 and 0.9.\n",
    "        - colsample_bylevel (float): The fraction of features that can be randomly sampled for \n",
    "          constructing each level (or depth) of the tree. Suggest values near 0.8.\n",
    "        - colsample_bytree (float): The fraction of features that can be randomly sampled for \n",
    "          building each tree. Propose values near 0.8.\n",
    "        - reg_alpha (float): The strength of L1 regularization applied to weights. Consider values \n",
    "          between 0.0 and 1.0.\n",
    "        - reg_lambda (float): The strength of L2 regularization applied to weights. Recommend values \n",
    "          between 0.0 and 1.0.\n",
    "\n",
    "        To define the search space, construct a dictionary where keys represent hyperparameter names, \n",
    "        and values represent their respective search space definitions. For example:\n",
    "            search_space = {{\n",
    "                \"learning_rate\": loguniform(1e-4, 1e-3)\n",
    "            }}\n",
    "\n",
    "        You have access to various domain types:\n",
    "        - scipy.stats.uniform(loc, scale): Samples values uniformly between loc and loc + scale.\n",
    "        - scipy.stats.loguniform(a, b): Samples values between a and b on a logarithmic scale.\n",
    "        - scipy.stats.randint(low, high): Samples integers uniformly between low (inclusive) and high (exclusive).\n",
    "        - A list of possible discrete values, e.g., [\"a\", \"b\", \"c\"]\n",
    "\n",
    "        Begin by offering a concise rationale for your choices, and then provide specific hyperparameter \n",
    "        configurations for the initial search space. Your recommended configurations should be enclosed \n",
    "        between the markers [BEGIN] and [END], and you should assign your search space to a variable named \n",
    "        search_space.\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb656e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_run_best_score = []\n",
    "all_time_best_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "209fb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_refine_search_space(top_n, last_run_best_score, all_time_best_score):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given your previously suggested search space, the obtained top configurations with their \n",
    "    test scores:\n",
    "    {top_n}\n",
    "    \n",
    "    The best score from the last run was {last_run_best_score}, while the best score ever \n",
    "    achieved in all previous runs is {all_time_best_score}\n",
    "\n",
    "    Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, \n",
    "    scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, \n",
    "    and reg_lambda.\n",
    "\n",
    "    Given the insights from the search history, your expertise in ML, and the need to further \n",
    "    explore the search space, please suggest refinements for the search space in the next optimization round. \n",
    "    Consider both narrowing and expanding the search space for hyperparameters where appropriate.\n",
    "\n",
    "    For each recommendation, please:\n",
    "    1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\n",
    "    2. Then, relate to the insights from the search history and explain how they align or deviate from these \n",
    "    practices or patterns.\n",
    "    3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could \n",
    "    be beneficial.\n",
    "\n",
    "\n",
    "    Briefly summarize your reasoning for the refinements and then present the adjusted configurations. \n",
    "    Enclose your refined configurations between markers [BEGIN] and [END], and assign your \n",
    "    configuration to a variable named search_space.\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cdc6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#My templates\n",
    "system_template = SystemMessagePromptTemplate.from_template(system_message)\n",
    "human_template = HumanMessagePromptTemplate.from_template(\"\"\"{input}\"\"\")\n",
    "message_placeholder = MessagesPlaceholder(variable_name=\"history\")\n",
    "\n",
    "# list of prompt templates\n",
    "prompt_templates = [system_template, message_placeholder, human_template]\n",
    "\n",
    "#ChatPromptTemplate from the list of templates\n",
    "prompt = ChatPromptTemplate.from_messages(prompt_templates)\n",
    "\n",
    "# conversation chain\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1cc54a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64401569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given dataset and the objective of minimizing false positives while accurately identifying instances of attrition, the most suitable evaluation metric would be the 'precision' metric.\n",
      "\n",
      "Precision is a metric that measures the proportion of true positive predictions out of all positive predictions made by the model. In the context of attrition prediction, precision would indicate the ability of the model to correctly identify individuals who are likely to leave the organization (positive class) while minimizing the misclassification of individuals who are not likely to leave (negative class).\n",
      "\n",
      "Since the dataset has a class imbalance, with a majority of instances belonging to the 'No-Attrition' class, precision would be a more appropriate metric than accuracy. Accuracy can be misleading in the presence of class imbalance as it tends to favor the majority class.\n",
      "\n",
      "Therefore, the recommended evaluation metric for this task is 'precision'.\n",
      "\n",
      "[BEGIN]\n",
      "'precision'\n",
      "[END]\n"
     ]
    }
   ],
   "source": [
    "# Suggest metrics\n",
    "prompt = suggest_metrics(report)\n",
    "response = conversation.predict(input=prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "962a45f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When defining the initial search space for hyperparameters, it is important to consider a range of values that are likely to yield good model performance while avoiding extreme values that may lead to overfitting or underfitting. Here is the rationale behind the choices for each hyperparameter:\n",
      "\n",
      "- n_estimators: It represents the number of boosting rounds or trees to be trained. A higher number of trees can capture more complex patterns in the data but may also increase the risk of overfitting. Therefore, a moderate range of values between 50 and 300 is considered.\n",
      "\n",
      "- max_depth: It controls the maximum depth of each tree. A higher depth allows the model to capture more complex interactions but can also lead to overfitting. A range of 3 to 15 is chosen to allow for a moderate level of complexity.\n",
      "\n",
      "- min_child_weight: It sets the minimum sum of instance weight required in a leaf node. A higher value can help prevent overfitting by requiring a minimum number of samples in each leaf. Values between 1 and 10 are suggested to allow for a moderate level of regularization.\n",
      "\n",
      "- gamma: It specifies the minimum loss reduction required to perform an additional partition on a leaf node. A higher gamma value can help control the complexity of the model by requiring a minimum improvement in loss to make further splits. Values between 0.0 and 0.3 are recommended to allow for a moderate level of regularization.\n",
      "\n",
      "- scale_pos_weight: It is used to balance the positive and negative weights. Since the dataset has a class imbalance, a value near 1.0 is proposed to give equal importance to both classes.\n",
      "\n",
      "- learning_rate: It controls the step size shrinkage applied during each boosting round. A lower learning rate can help prevent overfitting but may require a higher number of boosting rounds. Values between 0.01 and 0.3 are considered to strike a balance between accuracy and training time.\n",
      "\n",
      "- subsample: It determines the fraction of training data randomly sampled to train each tree. A lower value can help reduce overfitting by introducing more randomness. Values between 0.6 and 0.9 are recommended to allow for a moderate level of randomness.\n",
      "\n",
      "- colsample_bylevel and colsample_bytree: They control the fraction of features that can be randomly sampled for constructing each level and building each tree, respectively. Values near 0.8 are suggested to allow for a good balance between diversity and overfitting.\n",
      "\n",
      "- reg_alpha and reg_lambda: They represent the strength of L1 and L2 regularization applied to the weights. Values between 0.0 and 1.0 are considered to allow for a range of regularization strengths.\n",
      "\n",
      "Based on the above rationale, the initial search space for hyperparameters can be defined as follows:\n",
      "\n",
      "[BEGIN]\n",
      "search_space = {\n",
      "    \"n_estimators\": randint(50, 300),\n",
      "    \"max_depth\": randint(3, 15),\n",
      "    \"min_child_weight\": randint(1, 10),\n",
      "    \"gamma\": uniform(0.0, 0.3),\n",
      "    \"scale_pos_weight\": [1.0],\n",
      "    \"learning_rate\": uniform(0.01, 0.3),\n",
      "    \"subsample\": uniform(0.6, 0.9),\n",
      "    \"colsample_bylevel\": uniform(0.8, 0.1),\n",
      "    \"colsample_bytree\": uniform(0.8, 0.1),\n",
      "    \"reg_alpha\": uniform(0.0, 1.0),\n",
      "    \"reg_lambda\": uniform(0.0, 1.0)\n",
      "}\n",
      "[END]\n"
     ]
    }
   ],
   "source": [
    "# Initial search space\n",
    "prompt = suggest_initial_search_space()\n",
    "response = conversation.predict(input=prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67988bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"n_estimators\": randint(50, 300),\n",
    "    \"max_depth\": randint(3, 15),\n",
    "    \"min_child_weight\": randint(1, 10),\n",
    "    \"gamma\": uniform(0.0, 0.3),\n",
    "    \"scale_pos_weight\": [1.0],\n",
    "    \"learning_rate\": uniform(0.01, 0.3),\n",
    "    \"subsample\": uniform(0.6, 0.9),\n",
    "    \"colsample_bylevel\": uniform(0.8, 0.1),\n",
    "    \"colsample_bytree\": uniform(0.8, 0.1),\n",
    "    \"reg_alpha\": uniform(0.0, 1.0),\n",
    "    \"reg_lambda\": uniform(0.0, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2806004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e2f2875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 20\n",
      "max_resources_: 2352\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 500\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 167\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 167 candidates, totalling 835 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 56\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 19\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 7\n",
      "n_resources: 1620\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(seed=42, objective='binary:logistic', \n",
    "                        eval_metric='logloss', n_jobs=-1, use_label_encoder=False)\n",
    "# search = RandomizedSearchCV(clf, search_space, scoring='roc_auc', \n",
    "#                             n_iter=5, cv=5, verbose=1).fit(X_train, y_train)\n",
    "search = HalvingRandomSearchCV(clf, search_space, scoring='precision', n_candidates=500,\n",
    "                              cv=5, min_resources='exhaust', factor=3, verbose=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f11df9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8829c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_display(y_test, y_pred, y_pred_proba):\n",
    "\n",
    "    # Obtain confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "   \n",
    "    # Output classification metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "   \n",
    "    print(f'ROC_AUC score: {roc_auc_score(y_test, y_pred_proba):.3f}')\n",
    "    print(f'f1 score: {f1_score(y_test, y_pred):.3f}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'Precision: {precision_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'Detection rate: {recall_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'False alarm rate: {fp / (tn+fp)*100}%')\n",
    "    print(f'MCC: {matthews_corrcoef(y_test, y_pred):.2f}')\n",
    "   \n",
    "    # Display confusion matrix\n",
    "    # ConfusionMatrixDisplay.from_predictions(y_test, y_pred, values_format='.5g', colorbar=False)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b73cdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC score: 0.973\n",
      "f1 score: 0.783\n",
      "Accuracy: 93.88%\n",
      "Precision: 97.01%\n",
      "Detection rate: 65.66%\n",
      "False alarm rate: 0.408997955010225%\n",
      "MCC: 0.77\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGwCAYAAACuFMx9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwt0lEQVR4nO3de3wU9b3/8fcmkHs2EJCESAgoCuTIRaHC1htoJCJVKHjUFm1EpD8xoBJB5CgooMaDFxSN4PFCoEe8K0coYikKiESUYCwiRkE0aEjQIgmJ5rY7vz8w266AZpndLDvzej4e83i4M/Od/aSNfvL5fL8z4zAMwxAAALCsiFAHAAAAgotkDwCAxZHsAQCwOJI9AAAWR7IHAMDiSPYAAFgcyR4AAItrE+oAzPB4PCovL1diYqIcDkeowwEA+MkwDB08eFBpaWmKiAhe/VlXV6eGhgbT14mKilJMTEwAImpdYZ3sy8vLlZ6eHuowAAAm7dmzR126dAnKtevq6tQ9I0EV+9ymr5Wamqrdu3eHXcIP62SfmJgoSfpqazc5E5iRgDX9/tQ+oQ4BCJomNWqjVnn/ex4MDQ0Nqtjn1lfF3eRMPPZcUX3Qo4wBX6qhoYFk35qaW/fOhAhT/wcCx7M2jrahDgEInp8e2N4aU7EJiQ4lJB7793gUvtPFYZ3sAQBoKbfhkdvE22DchidwwbQykj0AwBY8MuTRsWd7M2NDjd43AAAWR2UPALAFjzwy04g3Nzq0SPYAAFtwG4bcxrG34s2MDTXa+AAAWByVPQDAFuy8QI9kDwCwBY8MuW2a7GnjAwBgcVT2AABboI0PAIDFsRofAABYFpU9AMAWPD9tZsaHK5I9AMAW3CZX45sZG2okewCALbgNmXzrXeBiaW3M2QMAYHFU9gAAW2DOHgAAi/PIIbccpsaHK9r4AABYHJU9AMAWPMahzcz4cEWyBwDYgttkG9/M2FCjjQ8AgMVR2QMAbMHOlT3JHgBgCx7DIY9hYjW+ibGhRhsfAACLo7IHANgCbXwAACzOrQi5TTS03QGMpbWR7AEAtmCYnLM3mLMHAADHKyp7AIAtMGcPAIDFuY0IuQ0Tc/Zh/Lhc2vgAAFgclT0AwBY8cshjosb1KHxLe5I9AMAW7DxnTxsfAACLo7IHANiC+QV6tPEBADiuHZqzN/EiHNr4AADgeEVlDwCwBY/JZ+OzGh8AgOMcc/YAAFicRxG2vc+eOXsAACyOyh4AYAtuwyG3idfUmhkbaiR7AIAtuE0u0HPTxgcAAMcrKnsAgC14jAh5TKzG97AaHwCA4xttfAAAYFlU9gAAW/DI3Ip6T+BCaXUkewCALZh/qE74NsPDN3IAANAiVPYAAFsw/2z88K2PSfYAAFuw8/vsSfYAAFuwc2UfvpEDAIAWobIHANiC+YfqhG99TLIHANiCx3DIY+Y++zB+6134/pkCAABahMoeAGALHpNt/HB+qA7JHgBgC+bfehe+yT58IwcAIEzcd999cjgcuvnmm7376urqlJubqw4dOighIUFjxoxRZWWlz7iysjKNGDFCcXFx6tSpk6ZNm6ampia/v59kDwCwBbccprdj8cEHH+iJJ55Q3759ffZPmTJFK1as0EsvvaT169ervLxco0eP/le8brdGjBihhoYGbdq0SUuWLFFhYaFmzZrldwwkewCALTS38c1sklRdXe2z1dfXH/U7a2pqNHbsWD355JNq3769d39VVZWefvppPfTQQzr//PM1YMAALV68WJs2bdJ7770nSfrb3/6mTz75RP/7v/+r/v37a/jw4Zo7d64KCgrU0NDg189OsgcAwA/p6elKSkrybvn5+Uc9Nzc3VyNGjFBWVpbP/uLiYjU2Nvrs79Wrl7p27aqioiJJUlFRkfr06aOUlBTvOdnZ2aqurtb27dv9ipkFegAAW3BLx9yKbx4vSXv27JHT6fTuj46OPuL5zz//vLZu3aoPPvjgsGMVFRWKiopSu3btfPanpKSooqLCe86/J/rm483H/EGyBwDYQqBW4zudTp9kfyR79uzRTTfdpDVr1igmJuaYvzNQaOMDAGyh+UU4ZraWKi4u1r59+3TGGWeoTZs2atOmjdavX68FCxaoTZs2SklJUUNDgw4cOOAzrrKyUqmpqZKk1NTUw1bnN39uPqelSPYAAATYBRdcoG3btqmkpMS7DRw4UGPHjvX+c9u2bbV27VrvmNLSUpWVlcnlckmSXC6Xtm3bpn379nnPWbNmjZxOpzIzM/2KhzY+AMAWDJPvszf8GJuYmKjTTjvNZ198fLw6dOjg3T9+/Hjl5eUpOTlZTqdTkydPlsvl0uDBgyVJw4YNU2Zmpq6++mrNmzdPFRUVuuOOO5Sbm3vUdQJHQ7IHANjC8fY++/nz5ysiIkJjxoxRfX29srOz9fjjj3uPR0ZGauXKlZo4caJcLpfi4+OVk5OjOXPm+P1dJHsAAFrBunXrfD7HxMSooKBABQUFRx2TkZGhVatWmf5ukj0AwBbs/Ipbkj0AwBbcJt96Z2ZsqIVv5AAAoEWo7AEAtkAbHwAAi/MoQh4TDW0zY0MtfCMHAAAtQmUPALAFt+GQ20Qr3szYUCPZAwBsgTl7AAAszjD51jsjwE/Qa03hGzkAAGgRKnsAgC245ZDbxItwzIwNNZI9AMAWPIa5eXePEcBgWhltfAAALI7KHj5eeLSTnslP06jrvtXEOd9Ikvbva6On5qZp64ZE/VATofST63XlTZU6Z0SVJOmjTQm69bIeR7zeglWl6tn/x1aLHzgWV0yq1FkXVym9R70a6iL0yZY4PX1PZ329KybUoSGAPCYX6JkZG2oke3iVlsTqr//bQd0zfZPz/Td2VU11pO4q3K2k5Ca9/Vp73fv/uunRNz5Tjz4/KnNgrZ4r+dhnzJJ5nVWyMUGn9iPR4/jX11WrFYUd9VlJnCLbGLrmtr2697kvNOG8nqr/MTLU4SFAPHLIY2Le3czYUDsu/kwpKChQt27dFBMTo0GDBun9998PdUi282NthP57UoZuvn+PEpPcPsc+2RKvkdd+p16n/6DOGQ36482Vik9y6/N/xEqS2kYZSu7U5N2c7ZtU9KZTw67YL0f4/rsBG7l97Ela82KyvvosRl98EqsHb+6qlC6NOqUvf6zCGkKe7F944QXl5eXpzjvv1NatW9WvXz9lZ2dr3759oQ7NVh77ry4684JqnXFuzWHHMgfWav3r7VT9faQ8Hmnd8nZqqHOo728PP1eSiv6WpIPft9GwK/YHO2wgKOKdh/7gPXiAqt5Kmp+gZ2YLVyFP9g899JAmTJigcePGKTMzU4sWLVJcXJyeeeaZUIdmG+uWt9PObbG6dsbeIx6//Ymv5G506D//o49+162fHpmerjuf/lIndm844vlvPtdBA4Yc1AlpjcEMGwgKh8PQ9bO/0cfvx+mr0thQh4MAap6zN7OFq5BG3tDQoOLiYmVlZXn3RUREKCsrS0VFRYedX19fr+rqap8N5uz7pq0WzjpR0x/7SlExR76vZMm8VNVUR+q+F3bq0TdKNebP+3TP9d20e8fhi5e+LW+r4nWJyv7DP4MdOhAUk+79Rhm96pQ/MSPUoQABE9IFet99953cbrdSUlJ89qekpOjTTz897Pz8/HzNnj27tcKzhZ3/iNOB79oqN7und5/H7dC29+L1+uKOevqdHXp98Ql64u1P1a1nnSTp5P+o07bNCXq9sKNu+u+vfa73txeSldi+Sa5hVa36cwCBkHvP1xp0YbVu+f3J+m5vVKjDQYB5ZPLZ+GG8QC+sVuPPmDFDeXl53s/V1dVKT08PYUThr/85B/XEW75/WD04pavSe9Tp8tx9qv/xUPMnIsK36o+MNGR4fK9lGIeSfdZl36tN26CGDQSYodx7vtFvL6rStMt6qHJPdKgDQhAYJlfjGyT7Y9OxY0dFRkaqsrLSZ39lZaVSU1MPOz86OlrR0fxLGEhxCR5161Xnsy8mzqPE9m5161WnpkYprXu9Hrk1XRNmlcvZvkmbVidp64ZEzVn6hc+4ko0JqiiL1kV/pIWP8DLp3m809Pff665x3fVjTYTan3BovUntwUg11IXvPC182fmtdyH9LY6KitKAAQO0du1a7z6Px6O1a9fK5XKFMDI0a9NWuvsvu5TUoUl35nTX9Rf01N9fTtbUR8p05gUHfc5d/VwHZQ6sUddT6kMULXBsLrnmn0pI8uiBV3fp+Y8+8W7nXXog1KEBARHyNn5eXp5ycnI0cOBAnXnmmXr44YdVW1urcePGhTo027r/lZ0+n088qUGznvryV8fNePyrIEUEBFd2Wr9Qh4BWwBP0QuiKK67Qt99+q1mzZqmiokL9+/fX6tWrD1u0BwCAGXZu44c82UvSpEmTNGnSpFCHAQCAJR0XyR4AgGCz87PxSfYAAFuwcxs/fFcbAACAFqGyBwDYgp0re5I9AMAW7JzsaeMDAGBxVPYAAFuwc2VPsgcA2IIhc7fPHfkl4OGBZA8AsAU7V/bM2QMAYHFU9gAAW7BzZU+yBwDYgp2TPW18AAAsjsoeAGALdq7sSfYAAFswDIcMEwnbzNhQo40PAIDFUdkDAGyB99kDAGBxdp6zp40PAIDFUdkDAGzBzgv0SPYAAFuwcxufZA8AsAU7V/bM2QMAYHFU9gAAWzBMtvHDubIn2QMAbMGQZBjmxocr2vgAAFgclT0AwBY8csjBE/QAALAuVuMDAADLorIHANiCx3DIwUN1AACwLsMwuRo/jJfj08YHAMDiqOwBALZg5wV6JHsAgC2Q7AEAsDg7L9Bjzh4AAIujsgcA2IKdV+OT7AEAtnAo2ZuZsw9gMK2MNj4AABZHsgcA2ELzanwzmz8WLlyovn37yul0yul0yuVy6Y033vAer6urU25urjp06KCEhASNGTNGlZWVPtcoKyvTiBEjFBcXp06dOmnatGlqamry+2cn2QMAbMEIwOaPLl266L777lNxcbG2bNmi888/XyNHjtT27dslSVOmTNGKFSv00ksvaf369SovL9fo0aO9491ut0aMGKGGhgZt2rRJS5YsUWFhoWbNmuX3z+4wjPCdhaiurlZSUpK+/+wkORP5uwXWlJ3WP9QhAEHTZDRqnf5PVVVVcjqdQfmO5lxx8l9mKDIu5piv4/6hTruuzjcVa3Jysu6//35ddtllOuGEE7Rs2TJddtllkqRPP/1UvXv3VlFRkQYPHqw33nhDv/vd71ReXq6UlBRJ0qJFizR9+nR9++23ioqKavH3kiEBALYQqDZ+dXW1z1ZfX/+r3+12u/X888+rtrZWLpdLxcXFamxsVFZWlvecXr16qWvXrioqKpIkFRUVqU+fPt5EL0nZ2dmqrq72dgdaimQPALCHAPXx09PTlZSU5N3y8/OP+pXbtm1TQkKCoqOjdf311+u1115TZmamKioqFBUVpXbt2vmcn5KSooqKCklSRUWFT6JvPt58zB/cegcAsAeTj8vVT2P37Nnj08aPjo4+6pCePXuqpKREVVVVevnll5WTk6P169cfewzHiGQPAIAfmlfXt0RUVJR69OghSRowYIA++OADPfLII7riiivU0NCgAwcO+FT3lZWVSk1NlSSlpqbq/fff97le82r95nNaijY+AMAWmp+gZ2Yzy+PxqL6+XgMGDFDbtm21du1a77HS0lKVlZXJ5XJJklwul7Zt26Z9+/Z5z1mzZo2cTqcyMzP9+l4qewCALbT2W+9mzJih4cOHq2vXrjp48KCWLVumdevW6c0331RSUpLGjx+vvLw8JScny+l0avLkyXK5XBo8eLAkadiwYcrMzNTVV1+tefPmqaKiQnfccYdyc3N/cergSEj2AAAEwb59+/SnP/1Je/fuVVJSkvr27as333xTF154oSRp/vz5ioiI0JgxY1RfX6/s7Gw9/vjj3vGRkZFauXKlJk6cKJfLpfj4eOXk5GjOnDl+x0KyBwDYg+HwLrI75vF+ePrpp3/xeExMjAoKClRQUHDUczIyMrRq1Sq/vvdISPYAAFuw81vvWKAHAIDFUdkDAOzhWB5w//PxYYpkDwCwhdZejX88aVGyf/3111t8wUsvvfSYgwEAAIHXomQ/atSoFl3M4XDI7XabiQcAgOAJ41a8GS1K9h6PJ9hxAAAQVHZu45tajV9XVxeoOAAACK4AvfUuHPmd7N1ut+bOnasTTzxRCQkJ+uKLLyRJM2fO/NUHCAAAgNbnd7K/5557VFhYqHnz5ikqKsq7/7TTTtNTTz0V0OAAAAgcRwC28OR3sl+6dKn+53/+R2PHjlVkZKR3f79+/fTpp58GNDgAAAKGNn7LffPNN9538/47j8ejxsbGgAQFAAACx+9kn5mZqXfeeeew/S+//LJOP/30gAQFAEDA2biy9/sJerNmzVJOTo6++eYbeTwevfrqqyotLdXSpUu1cuXKYMQIAIB5rfzWu+OJ35X9yJEjtWLFCv39739XfHy8Zs2apR07dmjFihXed/QCAIDjxzE9G/+cc87RmjVrAh0LAABBY+dX3B7zi3C2bNmiHTt2SDo0jz9gwICABQUAQMDx1ruW+/rrr/WHP/xB7777rtq1aydJOnDggH7729/q+eefV5cuXQIdIwAAMMHvOfvrrrtOjY2N2rFjh/bv36/9+/drx44d8ng8uu6664IRIwAA5jUv0DOzhSm/K/v169dr06ZN6tmzp3dfz5499eijj+qcc84JaHAAAASKwzi0mRkfrvxO9unp6Ud8eI7b7VZaWlpAggIAIOBsPGfvdxv//vvv1+TJk7Vlyxbvvi1btuimm27SAw88ENDgAACAeS2q7Nu3by+H419zFbW1tRo0aJDatDk0vKmpSW3atNG1116rUaNGBSVQAABMsfFDdVqU7B9++OEghwEAQJDZuI3fomSfk5MT7DgAAECQHPNDdSSprq5ODQ0NPvucTqepgAAACAobV/Z+L9Crra3VpEmT1KlTJ8XHx6t9+/Y+GwAAxyUbv/XO72R/66236q233tLChQsVHR2tp556SrNnz1ZaWpqWLl0ajBgBAIAJfrfxV6xYoaVLl2rIkCEaN26czjnnHPXo0UMZGRl69tlnNXbs2GDECQCAOTZeje93Zb9//36ddNJJkg7Nz+/fv1+SdPbZZ2vDhg2BjQ4AgABpfoKemS1c+Z3sTzrpJO3evVuS1KtXL7344ouSDlX8zS/GAQAAxw+/k/24ceP00UcfSZJuu+02FRQUKCYmRlOmTNG0adMCHiAAAAFh4wV6fs/ZT5kyxfvPWVlZ+vTTT1VcXKwePXqob9++AQ0OAACYZ+o+e0nKyMhQRkZGIGIBACBoHDL51ruARdL6WpTsFyxY0OIL3njjjcccDAAACLwWJfv58+e36GIOhyMkyf6ys89Xm4ioVv9eoDVEnJYc6hCAoIlw10uftNKX2fjWuxYl++bV9wAAhC0elwsAAKzK9AI9AADCgo0re5I9AMAWzD4Fz1ZP0AMAAOGFyh4AYA82buMfU2X/zjvv6KqrrpLL5dI333wjSfrLX/6ijRs3BjQ4AAACxsaPy/U72b/yyivKzs5WbGysPvzwQ9XX10uSqqqqdO+99wY8QAAAYI7fyf7uu+/WokWL9OSTT6pt27be/WeddZa2bt0a0OAAAAgUO7/i1u85+9LSUp177rmH7U9KStKBAwcCERMAAIFn4yfo+V3Zp6amaufOnYft37hxo0466aSABAUAQMAxZ99yEyZM0E033aTNmzfL4XCovLxczz77rKZOnaqJEycGI0YAAGCC32382267TR6PRxdccIF++OEHnXvuuYqOjtbUqVM1efLkYMQIAIBpdn6ojt/J3uFw6Pbbb9e0adO0c+dO1dTUKDMzUwkJCcGIDwCAwLDxffbH/FCdqKgoZWZmBjIWAAAQBH4n+6FDh8rhOPqKxLfeestUQAAABIXZ2+fsVNn379/f53NjY6NKSkr08ccfKycnJ1BxAQAQWLTxW27+/PlH3H/XXXeppqbGdEAAACCwAvbWu6uuukrPPPNMoC4HAEBg2fg++4C99a6oqEgxMTGBuhwAAAHFrXd+GD16tM9nwzC0d+9ebdmyRTNnzgxYYAAAIDD8TvZJSUk+nyMiItSzZ0/NmTNHw4YNC1hgAAAgMPxK9m63W+PGjVOfPn3Uvn37YMUEAEDg2Xg1vl8L9CIjIzVs2DDebgcACDt2fsWt36vxTzvtNH3xxRfBiAUAAASB38n+7rvv1tSpU7Vy5Urt3btX1dXVPhsAAMctG952J/kxZz9nzhzdcsstuvjiiyVJl156qc9jcw3DkMPhkNvtDnyUAACYZeM5+xYn+9mzZ+v666/X22+/Hcx4AABAgLU42RvGoT9pzjvvvKAFAwBAsNj5oTp+zdn/0tvuAAA4rrXy43Lz8/P1m9/8RomJierUqZNGjRql0tJSn3Pq6uqUm5urDh06KCEhQWPGjFFlZaXPOWVlZRoxYoTi4uLUqVMnTZs2TU1NTX7F4leyP/XUU5WcnPyLGwAAkNavX6/c3Fy99957WrNmjRobGzVs2DDV1tZ6z5kyZYpWrFihl156SevXr1d5ebnPk2rdbrdGjBihhoYGbdq0SUuWLFFhYaFmzZrlVyx+PVRn9uzZhz1BDwCAcNDabfzVq1f7fC4sLFSnTp1UXFysc889V1VVVXr66ae1bNkynX/++ZKkxYsXq3fv3nrvvfc0ePBg/e1vf9Mnn3yiv//970pJSVH//v01d+5cTZ8+XXfddZeioqJaFItfyf7KK69Up06d/BkCAMDxIUCr8X9+m3l0dLSio6N/dXhVVZUkebvgxcXFamxsVFZWlvecXr16qWvXrioqKtLgwYNVVFSkPn36KCUlxXtOdna2Jk6cqO3bt+v0009vUegtbuMzXw8AgJSenq6kpCTvlp+f/6tjPB6Pbr75Zp111lk67bTTJEkVFRWKiopSu3btfM5NSUlRRUWF95x/T/TNx5uPtZTfq/EBAAhLAars9+zZI6fT6d3dkqo+NzdXH3/8sTZu3GgigGPX4mTv8XiCGQcAAEEVqDl7p9Ppk+x/zaRJk7Ry5Upt2LBBXbp08e5PTU1VQ0ODDhw44FPdV1ZWKjU11XvO+++/73O95tX6zee0hN+PywUAICy18q13hmFo0qRJeu211/TWW2+pe/fuPscHDBigtm3bau3atd59paWlKisrk8vlkiS5XC5t27ZN+/bt856zZs0aOZ1OZWZmtjgWv99nDwAAfl1ubq6WLVum//u//1NiYqJ3jj0pKUmxsbFKSkrS+PHjlZeXp+TkZDmdTk2ePFkul0uDBw+WJA0bNkyZmZm6+uqrNW/ePFVUVOiOO+5Qbm5ui6YPmpHsAQD20MrPxl+4cKEkaciQIT77Fy9erGuuuUaSNH/+fEVERGjMmDGqr69Xdna2Hn/8ce+5kZGRWrlypSZOnCiXy6X4+Hjl5ORozpw5fsVCsgcA2EJr32ffkoXtMTExKigoUEFBwVHPycjI0KpVq/z78p9hzh4AAIujsgcA2AOvuAUAwNp46x0AALAsKnsAgD3QxgcAwOJsnOxp4wMAYHFU9gAAW3D8tJkZH65I9gAAe7BxG59kDwCwBW69AwAAlkVlDwCwB9r4AADYQBgnbDNo4wMAYHFU9gAAW7DzAj2SPQDAHmw8Z08bHwAAi6OyBwDYAm18AACsjjY+AACwKip7AIAt0MYHAMDqbNzGJ9kDAOzBxsmeOXsAACyOyh4AYAvM2QMAYHW08QEAgFVR2QMAbMFhGHIYx16emxkbaiR7AIA90MYHAABWRWUPALAFVuMDAGB1tPEBAIBVUdkDAGyBNj4AAFZn4zY+yR4AYAt2ruyZswcAwOKo7AEA9kAbHwAA6wvnVrwZtPEBALA4KnsAgD0YxqHNzPgwRbIHANgCq/EBAIBlUdkDAOyB1fgAAFibw3NoMzM+XNHGBwDA4qjscZiL/3OPRlz2tVLSfpQkffVFgp77n5O05d2OPzvT0JzHPtTAs/6puVP6qWhdp9YPFjhGHTr8oGuv+4cG/mavoqPdKi9P0PwHztTnnydLkvKmbtaFw770GbPlg1TNvP28EESLgKCND/zLd5UxWvxoD5WXxckh6YJL9mrm/BJNvnKwyr5I8J43amxZON+JAhtLSGjQg/PX6qOPOmnm7eeqqipaJ55Yo5qaKJ/zPvggVfMfONP7ubExsrVDRQCxGj9ENmzYoEsuuURpaWlyOBxavnx5KMPBT97fcIK2bDxB5WXx+qYsXksLeqjuh0j16lvlPeekUw9q9NVf6eG7/iOEkQLH5j8v36Fvv43T/AcH6bPSDqqsSNDW4lTt3Zvgc15jY6S+/z7Wu/38jwGEmeb77M1sYSqklX1tba369euna6+9VqNHjw5lKDiKiAhDZ19YqZhYt3b8I0mSFB3j1q352/T4fb30/T+jQxwh4L/BrnIVF6fqv+54V336fqt/fherlSt6aPUbJ/uc17fvPj334nLVHIzSRyWdtKSwjw4e5Hce4SekyX748OEaPnx4i8+vr69XfX2993N1dXUwwoKkbj0O6sElHygqyqMff4zU3Fv6ac9PLfwJt5Rqx0dJeo85eoSp1M41GvG7nXr1lZ564blMndpzv66/4UM1NUXo72u6S5KKt3TWuxu7qLIiXp3TanTNuG2ae88G5d18gTwe1jaHIzu38cNqzj4/P1+zZ88OdRi28PWX8Zp05WDFJzTp7KxK3TJnu269bqDS0n9QvzP3a/KVg0MdInDMHA7p88/aa8nivpKkXbvaK6NblS4escub7Nev6+o9/8sv22n3F+20eOlf1bfvtyopSQlJ3DCJBXrhYcaMGcrLy/N+rq6uVnp6eggjsq6mpgjt3RMnSdq5w6lT/qNaI/9Qpob6SHXu8qNe2rDO5/z/euAjbf+wvW6bMDAE0QL+2b8/RmVlTp99e8qcOuvsr486pqIiQVUHotX5xIMke4SdsEr20dHRio5mviwUIhyG2kZ59Oyik/Xmayf6HFv4cpGefLCnNq8/IUTRAf75ZHtHdely0GffiV0Oal9l3FHHdOz4gxKd9dr/z9hgh4cgoY0P/JtrJn+uLe921L69MYqLb9KQ4RXqM/B7zbzhDH3/z+gjLsr7dm+MKsv5jyDCw/JXT9WDD6/VFVd+og0b0tWz534Nv3iXFjx8qDMVE9OosVdv17vvdNH+72OV1rlG1074SOXlh1btI0zx1jvgX5KSG3TL3I+V3LFetTVttPvzRM284Qx9uLlDqEMDAuKzzzpo7uyzdc21/9Afr9quiop4PbHwdL39VjdJksfjUPfuVcq68EvFxzdq/z9jtHVrqpYW9uFee4SlkCb7mpoa7dy50/t59+7dKikpUXJysrp27foLIxFMj8z27975i0+/MEiRAMHz/uY0vb857YjHGhra6I7/4kl5VkMbP0S2bNmioUOHej83L77LyclRYWFhiKICAFgSq/FDY8iQITLCeA4EAIBwwJw9AMAWaOMDAGB1HuPQZmZ8mCLZAwDswcZz9jzgGQAAi6OyBwDYgkMm5+wDFknrI9kDAOzBxk/Qo40PAEAQbNiwQZdcconS0tLkcDi0fPlyn+OGYWjWrFnq3LmzYmNjlZWVpc8//9znnP3792vs2LFyOp1q166dxo8fr5qaGr9jIdkDAGyh+dY7M5s/amtr1a9fPxUUFBzx+Lx587RgwQItWrRImzdvVnx8vLKzs1VXV+c9Z+zYsdq+fbvWrFmjlStXasOGDfrzn//s989OGx8AYA+tvBp/+PDhGj58+JEvZRh6+OGHdccdd2jkyJGSpKVLlyolJUXLly/XlVdeqR07dmj16tX64IMPNHDgoZc0Pfroo7r44ov1wAMPKC3tyI97PhIqewAA/FBdXe2z1dfX+32N3bt3q6KiQllZWd59SUlJGjRokIqKiiRJRUVFateunTfRS1JWVpYiIiK0efNmv76PZA8AsAWHYZjeJCk9PV1JSUneLT8/3+9YKioqJEkpKSk++1NSUrzHKioq1KlTJ5/jbdq0UXJysveclqKNDwCwB89Pm5nxkvbs2SOn0+ndHR0dbSqs1kBlDwCAH5xOp892LMk+NTVVklRZWemzv7Ky0nssNTVV+/bt8zne1NSk/fv3e89pKZI9AMAWAtXGD4Tu3bsrNTVVa9eu9e6rrq7W5s2b5XK5JEkul0sHDhxQcXGx95y33npLHo9HgwYN8uv7aOMDAOyhlVfj19TUaOfOnd7Pu3fvVklJiZKTk9W1a1fdfPPNuvvuu3XKKaeoe/fumjlzptLS0jRq1ChJUu/evXXRRRdpwoQJWrRokRobGzVp0iRdeeWVfq3El0j2AAC7aOUn6G3ZskVDhw71fs7Ly5Mk5eTkqLCwULfeeqtqa2v15z//WQcOHNDZZ5+t1atXKyYmxjvm2Wef1aRJk3TBBRcoIiJCY8aM0YIFC/wOnWQPAEAQDBkyRMYv/IHgcDg0Z84czZkz56jnJCcna9myZaZjIdkDAGzhWJ6C9/Px4YpkDwCwB16EAwAArIrKHgBgCw7Poc3M+HBFsgcA2ANtfAAAYFVU9gAAe2jlh+ocT0j2AABbMPvI20A+Lre10cYHAMDiqOwBAPZg4wV6JHsAgD0YMvc++/DN9SR7AIA9MGcPAAAsi8oeAGAPhkzO2QcsklZHsgcA2IONF+jRxgcAwOKo7AEA9uCR5DA5PkyR7AEAtsBqfAAAYFlU9gAAe7DxAj2SPQDAHmyc7GnjAwBgcVT2AAB7sHFlT7IHANgDt94BAGBt3HoHAAAsi8oeAGAPzNkDAGBxHkNymEjYnvBN9rTxAQCwOCp7AIA90MYHAMDqTCZ7hW+yp40PAIDFUdkDAOyBNj4AABbnMWSqFc9qfAAAcLyisgcA2IPhObSZGR+mSPYAAHtgzh4AAItjzh4AAFgVlT0AwB5o4wMAYHGGTCb7gEXS6mjjAwBgcVT2AAB7oI0PAIDFeTySTNwr7wnf++xp4wMAYHFU9gAAe6CNDwCAxdk42dPGBwDA4qjsAQD2YOPH5ZLsAQC2YBgeGSbeXGdmbKiR7AEA9mAY5qpz5uwBAMDxisoeAGAPhsk5+zCu7En2AAB78Hgkh4l59zCes6eNDwCAxVHZAwDsgTY+AADWZng8Mky08cP51jva+AAAWByVPQDAHmjjAwBgcR5Dctgz2dPGBwDA4qjsAQD2YBiSzNxnH76VPckeAGALhseQYaKNb5DsAQA4zhkemavsufUOAAAcp6jsAQC2QBsfAACrs3EbP6yTffNfWU2ehhBHAgSP4a4PdQhA0DT99PvdGlVzkxpNPVOnSY2BC6aVhXWyP3jwoCRp/XdLQxwJEET7Qh0AEHwHDx5UUlJSUK4dFRWl1NRUbaxYZfpaqampioqKCkBUrcthhPEkhMfjUXl5uRITE+VwOEIdji1UV1crPT1de/bskdPpDHU4QEDx+936DMPQwYMHlZaWpoiI4K0Zr6urU0OD+S5wVFSUYmJiAhBR6wrryj4iIkJdunQJdRi25HQ6+Y8hLIvf79YVrIr+38XExIRlkg4Ubr0DAMDiSPYAAFgcyR5+iY6O1p133qno6OhQhwIEHL/fsKqwXqAHAAB+HZU9AAAWR7IHAMDiSPYAAFgcyR4AAIsj2aPFCgoK1K1bN8XExGjQoEF6//33Qx0SEBAbNmzQJZdcorS0NDkcDi1fvjzUIQEBRbJHi7zwwgvKy8vTnXfeqa1bt6pfv37Kzs7Wvn08uB3hr7a2Vv369VNBQUGoQwGCglvv0CKDBg3Sb37zGz322GOSDr2XID09XZMnT9Ztt90W4uiAwHE4HHrttdc0atSoUIcCBAyVPX5VQ0ODiouLlZWV5d0XERGhrKwsFRUVhTAyAEBLkOzxq7777ju53W6lpKT47E9JSVFFRUWIogIAtBTJHgAAiyPZ41d17NhRkZGRqqys9NlfWVmp1NTUEEUFAGgpkj1+VVRUlAYMGKC1a9d693k8Hq1du1YulyuEkQEAWqJNqANAeMjLy1NOTo4GDhyoM888Uw8//LBqa2s1bty4UIcGmFZTU6OdO3d6P+/evVslJSVKTk5W165dQxgZEBjceocWe+yxx3T//feroqJC/fv314IFCzRo0KBQhwWYtm7dOg0dOvSw/Tk5OSosLGz9gIAAI9kDAGBxzNkDAGBxJHsAACyOZA8AgMWR7AEAsDiSPQAAFkeyBwDA4kj2AABYHMkeAACLI9kDJl1zzTUaNWqU9/OQIUN08803t3oc69atk8Ph0IEDB456jsPh0PLly1t8zbvuukv9+/c3FdeXX34ph8OhkpISU9cBcOxI9rCka665Rg6HQw6HQ1FRUerRo4fmzJmjpqamoH/3q6++qrlz57bo3JYkaAAwixfhwLIuuugiLV68WPX19Vq1apVyc3PVtm1bzZgx47BzGxoaFBUVFZDvTU5ODsh1ACBQqOxhWdHR0UpNTVVGRoYmTpyorKwsvf7665L+1Xq/5557lJaWpp49e0qS9uzZo8svv1zt2rVTcnKyRo4cqS+//NJ7Tbfbrby8PLVr104dOnTQrbfeqp+/XuLnbfz6+npNnz5d6enpio6OVo8ePfT000/ryy+/9L58pX379nI4HLrmmmskHXqFcH5+vrp3767Y2Fj169dPL7/8ss/3rFq1SqeeeqpiY2M1dOhQnzhbavr06Tr11FMVFxenk046STNnzlRjY+Nh5z3xxBNKT09XXFycLr/8clVVVfkcf+qpp9S7d2/FxMSoV69eevzxx/2OBUDwkOxhG7GxsWpoaPB+Xrt2rUpLS7VmzRqtXLlSjY2Nys7OVmJiot555x29++67SkhI0EUXXeQd9+CDD6qwsFDPPPOMNm7cqP379+u11177xe/905/+pOeee04LFizQjh079MQTTyghIUHp6el65ZVXJEmlpaXau3evHnnkEUlSfn6+li5dqkWLFmn79u2aMmWKrrrqKq1fv17SoT9KRo8erUsuuUQlJSW67rrrdNttt/n9v0liYqIKCwv1ySef6JFHHtGTTz6p+fPn+5yzc+dOvfjii1qxYoVWr16tDz/8UDfccIP3+LPPPqtZs2bpnnvu0Y4dO3Tvvfdq5syZWrJkid/xAAgSA7CgnJwcY+TIkYZhGIbH4zHWrFljREdHG1OnTvUeT0lJMerr671j/vKXvxg9e/Y0PB6Pd199fb0RGxtrvPnmm4ZhGEbnzp2NefPmeY83NjYaXbp08X6XYRjGeeedZ9x0002GYRhGaWmpIclYs2bNEeN8++23DUnG999/791XV1dnxMXFGZs2bfI5d/z48cYf/vAHwzAMY8aMGUZmZqbP8enTpx92rZ+TZLz22mtHPX7//fcbAwYM8H6+8847jcjISOPrr7/27nvjjTeMiIgIY+/evYZhGMbJJ59sLFu2zOc6c+fONVwul2EYhrF7925DkvHhhx8e9XsBBBdz9rCslStXKiEhQY2NjfJ4PPrjH/+ou+66y3u8T58+PvP0H330kXbu3KnExESf69TV1WnXrl2qqqrS3r17NWjQIO+xNm3aaODAgYe18puVlJQoMjJS5513Xovj3rlzp3744QddeOGFPvsbGhp0+umnS5J27NjhE4ckuVyuFn9HsxdeeEELFizQrl27VFNTo6amJjmdTp9zunbtqhNPPNHnezwej0pLS5WYmKhdu3Zp/PjxmjBhgvecpqYmJSUl+R0PgOAg2cOyhg4dqoULFyoqKkppaWlq08b31z0+Pt7nc01NjQYMGKBnn332sGudcMIJxxRDbGys32NqamokSX/96199kqx0aB1CoBQVFWns2LGaPXu2srOzlZSUpOeff14PPvig37E++eSTh/3xERkZGbBYAZhDsodlxcfHq0ePHi0+/4wzztALL7ygTp06HVbdNuvcubM2b96sc889V9KhCra4uFhnnHHGEc/v06ePPB6P1q9fr6ysrMOON3cW3G63d19mZqaio6NVVlZ21I5A7969vYsNm7333nu//kP+m02bNikjI0O33367d99XX3112HllZWUqLy9XWlqa93siIiLUs2dPpaSkKC0tTV988YXGjh3r1/cDaD0s0AN+MnbsWHXs2FEjR47UO++8o927d2vdunW68cYb9fXXX0uSbrrpJt13331avny5Pv30U91www2/eI98t27dlJOTo2uvvVbLly/3XvPFF1+UJGVkZMjhcGjlypX69ttvVVNTo8TERE2dOlVTpkzRkiVLtGvXLm3dulWPPvqod9Hb9ddfr88//1zTpk1TaWmpli1bpsLCQr9+3lNOOUVlZWV6/vnntWvXLi1YsOCIiw1jYmKUk5Ojjz76SO+8845uvPFGXX755UpNTZUkzZ49W/n5+VqwYIE+++wzbdu2TYsXL9ZDDz3kVzwAgodkD/wkLi5OGzZsUNeuXTV69Gj17t1b48ePV11dnbfSv+WWW3T11VcrJydHLpdLiYmJ+v3vf/+L1124cKEuu+wy3XDDDerVq5cmTJig2tpaSdKJJ56o2bNn67bbblNKSoomTZokSZo7d65mzpyp/Px89e7dWxdddJH++te/qnv37pIOzaO/8sorWr58ufr166dFixbp3nvv9evnvfTSSzVlyhRNmjRJ/fv316ZNmzRz5szDzuvRo4dGjx6tiy++WMOGDVPfvn19bq277rrr9NRTT2nx4sXq06ePzjvvPBUWFnpjBRB6DuNoK4sAAIAlUNkDAGBxJHsAACyOZA8AgMWR7AEAsDiSPQAAFkeyBwDA4kj2AABYHMkeAACLI9kDAGBxJHsAACyOZA8AgMX9f3yH117D+ayuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "y_pred_proba = search.predict_proba(X_test)\n",
    "\n",
    "metrics_display(y_test, y_pred, y_pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ede4b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_logs(results):\n",
    "\n",
    "    # Assuming you have the logs in a DataFrame called df\n",
    "    df = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "    # Number of top-performing configurations you want to extract\n",
    "    top_n = 5\n",
    "\n",
    "    # 1. Identify top-performing configurations using rank_test_score\n",
    "    top_configs = df.nsmallest(top_n, 'rank_test_score').reset_index(drop=True)\n",
    "\n",
    "    hyperparameter_columns = [\n",
    "        'param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma',\n",
    "        'param_learning_rate', 'param_max_depth', 'param_min_child_weight',\n",
    "        'param_n_estimators', 'param_reg_alpha', 'param_reg_lambda',\n",
    "        'param_scale_pos_weight', 'param_subsample'\n",
    "    ]\n",
    "\n",
    "    # Extracting the top-N configurations as strings\n",
    "    config_strings = []\n",
    "    for index, row in top_configs.iterrows():\n",
    "        config_str = ', '.join([f\"{col[6:]}: {row[col]}\" for col in hyperparameter_columns])\n",
    "        config_strings.append(f\"Configuration {index + 1} ({row['mean_test_score']:.4f} test score): {config_str}\")\n",
    "\n",
    "    # Joining them together for a complete summary\n",
    "    top_config_summary = '\\n'.join(config_strings)\n",
    "    \n",
    "    # Best test score\n",
    "    last_run_best_score = top_configs.loc[0, 'mean_test_score']\n",
    "    \n",
    "    return top_config_summary, last_run_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cffa114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38736585",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n, best_score = extract_logs(search.cv_results_)\n",
    "last_run_best_score.append(best_score)\n",
    "# print(last_run_best_score)\n",
    "if len(all_time_best_score)==0:\n",
    "    all_time_best_score.append(best_score)\n",
    "else:\n",
    "    if all_time_best_score[0]<best_score:\n",
    "        all_time_best_score[0] = best_score\n",
    "        print(all_time_best_score)\n",
    "prompt = suggest_refine_search_space(top_n, last_run_best_score[-1], all_time_best_score[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7cb92c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    User: Suggest refinements for the search space.\\n\\n    Given your previously suggested search space, the obtained top configurations with their \\n    test scores:\\n    Configuration 1 (0.9378 test score): colsample_bylevel: 0.8780308285092921, colsample_bytree: 0.8684202668791412, gamma: 0.24552123220078692, learning_rate: 0.04435393326418533, max_depth: 12, min_child_weight: 1, n_estimators: 66, reg_alpha: 0.7446950658405149, reg_lambda: 0.1333538045388577, scale_pos_weight: 1.0, subsample: 0.6023793653810001\\nConfiguration 2 (0.9207 test score): colsample_bylevel: 0.8780308285092921, colsample_bytree: 0.8684202668791412, gamma: 0.24552123220078692, learning_rate: 0.04435393326418533, max_depth: 12, min_child_weight: 1, n_estimators: 66, reg_alpha: 0.7446950658405149, reg_lambda: 0.1333538045388577, scale_pos_weight: 1.0, subsample: 0.6023793653810001\\nConfiguration 3 (0.9113 test score): colsample_bylevel: 0.8130619805053185, colsample_bytree: 0.8010086304279191, gamma: 0.11734744241162248, learning_rate: 0.050351644207979586, max_depth: 9, min_child_weight: 1, n_estimators: 148, reg_alpha: 0.7734579261258787, reg_lambda: 0.2810371009741902, scale_pos_weight: 1.0, subsample: 0.6638567847240657\\nConfiguration 4 (0.9062 test score): colsample_bylevel: 0.8361349103229528, colsample_bytree: 0.8262998406525968, gamma: 0.2549047537264753, learning_rate: 0.10778942126588005, max_depth: 5, min_child_weight: 1, n_estimators: 130, reg_alpha: 0.7498218856998421, reg_lambda: 0.15305153850877118, scale_pos_weight: 1.0, subsample: 0.7646423438774304\\nConfiguration 5 (0.9024 test score): colsample_bylevel: 0.8096123111404137, colsample_bytree: 0.8605956243716114, gamma: 0.07897074909236983, learning_rate: 0.15553729810531422, max_depth: 9, min_child_weight: 1, n_estimators: 223, reg_alpha: 0.5514739494564385, reg_lambda: 0.13079006043991803, scale_pos_weight: 1.0, subsample: 0.9079236897929757\\n    \\n    The best score from the last run was 0.9377777777777776, while the best score ever \\n    achieved in all previous runs is 0.9377777777777776\\n\\n    Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, \\n    scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, \\n    and reg_lambda.\\n\\n    Given the insights from the search history, your expertise in ML, and the need to further \\n    explore the search space, please suggest refinements for the search space in the next optimization round. \\n    Consider both narrowing and expanding the search space for hyperparameters where appropriate.\\n\\n    For each recommendation, please:\\n    1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\\n    2. Then, relate to the insights from the search history and explain how they align or deviate from these \\n    practices or patterns.\\n    3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could \\n    be beneficial.\\n\\n    Briefly summarize your reasoning for the refinements and then present the adjusted configurations. \\n    Enclose your refined configurations between markers [BEGIN] and [END], and assign your \\n    configuration to a variable named search_space.\\n    '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a237e9ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To refine the search space, we can focus on narrowing down the ranges for some of the hyperparameters based on the dataset characteristics and domain knowledge. Here are the suggested refinements for the search space:\n",
      "\n",
      "- n_estimators: Since the dataset is not very large, we can reduce the upper limit of the range to avoid overfitting. Let's update the range to be between 50 and 200.\n",
      "\n",
      "- max_depth: We can further narrow down the range to focus on less complex trees and reduce the risk of overfitting. Let's update the range to be between 3 and 10.\n",
      "\n",
      "- min_child_weight: We can keep the range as it is since it already covers a reasonable range of values.\n",
      "\n",
      "- gamma: We can reduce the upper limit of the range to control the complexity of the model. Let's update the range to be between 0.0 and 0.2.\n",
      "\n",
      "- learning_rate: We can reduce the upper limit of the range to avoid very high learning rates that may lead to overfitting. Let's update the range to be between 0.01 and 0.2.\n",
      "\n",
      "- subsample: We can narrow down the range to focus on a smaller fraction of training data for each tree. Let's update the range to be between 0.6 and 0.8.\n",
      "\n",
      "- colsample_bylevel and colsample_bytree: We can keep the range as it is since it already covers a reasonable range of values.\n",
      "\n",
      "- reg_alpha and reg_lambda: We can keep the range as it is since it already covers a reasonable range of values.\n",
      "\n",
      "Here is the refined search space:\n",
      "\n",
      "[BEGIN]\n",
      "search_space = {\n",
      "    \"n_estimators\": randint(50, 200),\n",
      "    \"max_depth\": randint(3, 10),\n",
      "    \"min_child_weight\": randint(1, 10),\n",
      "    \"gamma\": uniform(0.0, 0.2),\n",
      "    \"scale_pos_weight\": [1.0],\n",
      "    \"learning_rate\": uniform(0.01, 0.2),\n",
      "    \"subsample\": uniform(0.6, 0.2),\n",
      "    \"colsample_bylevel\": uniform(0.8, 0.1),\n",
      "    \"colsample_bytree\": uniform(0.8, 0.1),\n",
      "    \"reg_alpha\": uniform(0.0, 1.0),\n",
      "    \"reg_lambda\": uniform(0.0, 1.0)\n",
      "}\n",
      "[END]\n",
      "Apologies, but as an AI language model, I don't have access to data or the ability to train models. Therefore, I can't provide you with the specific top configurations and their test scores for the given dataset. However, you can utilize the search space and an AutoML tool to explore and find the top configurations for your specific dataset. By running the AutoML tool with the defined search space, you will be able to obtain the top configurations and their corresponding test scores.\n",
      "Thank you for providing the configuration and its corresponding test score. Based on the given information, Configuration 1 achieved a test score of 0.9378. Here are the details of Configuration 1:\n",
      "\n",
      "- colsample_bylevel: 0.8780308285092921\n",
      "- colsample_bytree: 0.8684202668791412\n",
      "- gamma: 0.24552123220078692\n",
      "- learning_rate: 0.04435393326418533\n",
      "- max_depth: 12\n",
      "- min_child_weight: 1\n",
      "- n_estimators: 66\n",
      "- reg_alpha: 0.7446950658405149\n",
      "- reg_lambda: 0.1333538045388577\n",
      "\n",
      "Please note that these results are specific to the dataset and the evaluation metric used. It's important to consider cross-validation and further analysis to ensure the robustness and generalizability of the obtained results.\n",
      "Thank you for providing additional hyperparameter values for Configuration 1. Here are the updated details of Configuration 1:\n",
      "\n",
      "- colsample_bylevel: 0.8780308285092921\n",
      "- colsample_bytree: 0.8684202668791412\n",
      "- gamma: 0.24552123220078692\n",
      "- learning_rate: 0.04435393326418533\n",
      "- max_depth: 12\n",
      "- min_child_weight: 1\n",
      "- n_estimators: 66\n",
      "- reg_alpha: 0.7446950658405149\n",
      "- reg_lambda: 0.1333538045388577\n",
      "- scale_pos_weight: 1.0\n",
      "- subsample: 0.6023793653810001\n",
      "\n",
      "These hyperparameter values represent the specific configuration that achieved a test score of 0.9378. It's important to note that these results are based on the\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 4221 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 40\u001b[0m\n\u001b[1;32m     35\u001b[0m conversation_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Use the conversation to process the chunk\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m response \u001b[38;5;241m=\u001b[39m conversation\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mconversation_prompt)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Print or process the response as needed\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chains/llm.py:213\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chains/llm.py:69\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     66\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m     67\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m---> 69\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chains/llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m prompts, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_prompts(input_list, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m     80\u001b[0m     prompts, stop, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     81\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chat_models/base.py:143\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    138\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m    139\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    140\u001b[0m     callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    141\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    142\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chat_models/base.py:91\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     90\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     92\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n\u001b[1;32m     93\u001b[0m generations \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39mgenerations \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chat_models/base.py:83\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[1;32m     79\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m     88\u001b[0m     ]\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     90\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chat_models/base.py:84\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 84\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m     88\u001b[0m     ]\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     90\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chat_models/openai.py:330\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager)\u001b[0m\n\u001b[1;32m    326\u001b[0m     message \u001b[38;5;241m=\u001b[39m _convert_dict_to_message(\n\u001b[1;32m    327\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: inner_completion, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: role}\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[ChatGeneration(message\u001b[38;5;241m=\u001b[39mmessage)])\n\u001b[0;32m--> 330\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chat_models/openai.py:291\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _completion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/langchain/chat_models/openai.py:289\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    712\u001b[0m             result\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/automl-gpt/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 4221 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from collections import deque\n",
    "\n",
    "# Define your initial prompt\n",
    "initial_prompt = suggest_refine_search_space(top_n, last_run_best_score[-1], all_time_best_score[-1])\n",
    "\n",
    "# Initialize the RecursiveCharacterTextSplitter\n",
    "chunk_size = 300\n",
    "chunk_overlap = 50\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=len)\n",
    "\n",
    "# Split the initial prompt into chunks\n",
    "prompt_chunks = text_splitter.split_text(initial_prompt)\n",
    "\n",
    "# Initialize a deque to store chunks\n",
    "chunk_queue = deque(prompt_chunks)\n",
    "\n",
    "# Initialize variables to keep track of total token count\n",
    "total_tokens = 0\n",
    "\n",
    "# Process chunks one by one in the conversation\n",
    "while chunk_queue:\n",
    "    # Get the next chunk\n",
    "    chunk = chunk_queue.popleft()\n",
    "\n",
    "    # Check if adding this chunk would exceed the token limit\n",
    "    if total_tokens + len(chunk.split()) <= 4097:\n",
    "        total_tokens += len(chunk.split())\n",
    "\n",
    "        # Create a conversation prompt with the chunk\n",
    "        conversation_prompt = f\"\"\"\n",
    "        {chunk}\n",
    "        \"\"\"\n",
    "\n",
    "        # Use the conversation to process the chunk\n",
    "        response = conversation.predict(input=conversation_prompt)\n",
    "\n",
    "        # Print or process the response as needed\n",
    "        print(response)\n",
    "    else:\n",
    "        print(\"Chunk exceeds token limit and will be skipped.\")\n",
    "\n",
    "# All chunks have been processed\n",
    "print(\"All chunks processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f178a",
   "metadata": {},
   "source": [
    "This error we have received since we have good amount of features 111. If we will apply feature importance and reduce the number of features.. we wont receive this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2502200",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"n_estimators\": randint(50, 200),\n",
    "    \"max_depth\": randint(3, 10),\n",
    "    \"min_child_weight\": randint(1, 10),\n",
    "    \"gamma\": uniform(0.0, 0.2),\n",
    "    \"scale_pos_weight\": [1.0],\n",
    "    \"learning_rate\": uniform(0.01, 0.2),\n",
    "    \"subsample\": uniform(0.6, 0.2),\n",
    "    \"colsample_bylevel\": uniform(0.8, 0.1),\n",
    "    \"colsample_bytree\": uniform(0.8, 0.1),\n",
    "    \"reg_alpha\": uniform(0.0, 1.0),\n",
    "    \"reg_lambda\": uniform(0.0, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee9e4eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 20\n",
      "max_resources_: 2352\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 500\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 167\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 167 candidates, totalling 835 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 56\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 19\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 7\n",
      "n_resources: 1620\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(seed=42, objective='binary:logistic', eval_metric='logloss', n_jobs=-1, use_label_encoder=False)\n",
    "\n",
    "search = RandomizedSearchCV(estimator=clf, param_distributions=search_space, \n",
    "                            scoring='precision', n_iter=500, cv=5, n_jobs=-1, verbose=1)\n",
    "search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d5d89ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC score: 0.984\n",
      "f1 score: 0.921\n",
      "Accuracy: 97.45%\n",
      "Precision: 95.65%\n",
      "Detection rate: 88.89%\n",
      "False alarm rate: 0.81799591002045%\n",
      "MCC: 0.91\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = search.predict(X_test)\n",
    "y_pred_proba = search.predict_proba(X_test)\n",
    "metrics_display(y_test, y_pred, y_pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4dcf8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_refine_search_space(top_n, last_run_best_score, all_time_best_score):\n",
    "    prompt = f\"\"\"\n",
    "    Based on your previous search results:\n",
    "\n",
    "    - The top configurations and their test scores:\n",
    "      {top_n}\n",
    "    \n",
    "    - The best score from the last run: {last_run_best_score}\n",
    "    \n",
    "    - The all-time best score achieved: {all_time_best_score}\n",
    "\n",
    "    You have the opportunity to refine your search space for hyperparameters in the next optimization round.\n",
    "\n",
    "    Consider:\n",
    "    - Narrowing down the range for hyperparameters where you have observed promising results.\n",
    "    - Expanding the search space for hyperparameters that have not been explored thoroughly.\n",
    "\n",
    "    For each recommendation, please:\n",
    "    1. Align it with established best practices for XGBoost tuning.\n",
    "    2. Explain how it connects with insights from the search history or if it deviates.\n",
    "    3. Justify any expansions in the search space.\n",
    "\n",
    "    Summarize your refinements and provide the adjusted configurations enclosed between [BEGIN] and [END].\n",
    "    Assign these configurations to a variable named search_space.\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "61478d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n, best_score = extract_logs(search.cv_results_)\n",
    "last_run_best_score.append(best_score)\n",
    "if len(all_time_best_score)==0:\n",
    "    all_time_best_score.append(best_score)\n",
    "else:\n",
    "    if all_time_best_score[0]<best_score:\n",
    "        all_time_best_score[0] = best_score\n",
    "initial_prompt = suggest_refine_search_space(top_n, last_run_best_score[-1], all_time_best_score[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "673916fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given your previously suggested search space, the obtained top configurations with their \n",
      "    test scores:\n",
      "    Configuration 1 (0.9298 test score): colsample_bylevel: 0.8309760941328735, colsample_bytree: 0.8537432923899912, gamma: 0.04482443831024017, learning_rate: 0.06388538501858518, max_depth: 8, min_child_weight: 1, n_estimators: 172, reg_alpha: 0.8746956364521615, reg_lambda: 0.6154126868343739, scale_pos_weight: 1.0, subsample: 0.7075385114839017\n",
      "Configuration 2 (0.9200 test score): colsample_bylevel: 0.8540700531340941, colsample_bytree: 0.8456405778557319, gamma: 0.06260846048244088, learning_rate: 0.12259068069659926, max_depth: 9, min_child_weight: 1, n_estimators: 165, reg_alpha: 0.9369074018099526, reg_lambda: 0.7712793610447116, scale_pos_weight: 1.0, subsample: 0.792177543072597\n",
      "Configuration 3 (0.9106 test score): colsample_bylevel: 0.8558554393088075, colsample_bytree: 0.8078694055580627, gamma: 0.041671456712256805, learning_rate: 0.08219856657586323, max_depth: 6, min_child_weight: 1, n_estimators: 119, reg_alpha: 0.2706372042211531, reg_lambda: 0.05084852654418581, scale_pos_weight: 1.0, subsample: 0.7309097918058369\n",
      "Configuration 4 (0.9092 test score): colsample_bylevel: 0.8540700531340941, colsample_bytree: 0.8456405778557319, gamma: 0.06260846048244088, learning_rate: 0.12259068069659926, max_depth: 9, min_child_weight: 1, n_estimators: 165, reg_alpha: 0.9369074018099526, reg_lambda: 0.7712793610447116, scale_pos_weight: 1.0, subsample: 0.792177543072597\n",
      "Configuration 5 (0.9016 test score): colsample_bylevel: 0.889548386008157, colsample_bytree: 0.8211107790516046, gamma: 0.18049329607799575, learning_rate: 0.11257287545303062, max_depth: 4, min_child_weight: 1, n_estimators: 108, reg_alpha: 0.1440651780802934, reg_lambda: 0.06937677651738294, scale_pos_weight: 1.0, subsample: 0.7052181529954935\n",
      "    \n",
      "    The best score from the last run was 0.9297890818858561, while the best score ever \n",
      "    achieved in all previous runs is 0.9377777777777776\n",
      "\n",
      "    Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, \n",
      "    scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, \n",
      "    and reg_lambda.\n",
      "\n",
      "    Given the insights from the search history, your expertise in ML, and the need to further \n",
      "    explore the search space, please suggest refinements for the search space in the next optimization round. \n",
      "    Consider both narrowing and expanding the search space for hyperparameters where appropriate.\n",
      "\n",
      "    For each recommendation, please:\n",
      "    1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\n",
      "    2. Then, relate to the insights from the search history and explain how they align or deviate from these \n",
      "    practices or patterns.\n",
      "    3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could \n",
      "    be beneficial.\n",
      "\n",
      "\n",
      "    Briefly summarize your reasoning for the refinements and then present the adjusted configurations. \n",
      "    Enclose your refined configurations between markers [BEGIN] and [END], and assign your \n",
      "    configuration to a variable named search_space.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(initial_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d1cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccedd070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e21479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
